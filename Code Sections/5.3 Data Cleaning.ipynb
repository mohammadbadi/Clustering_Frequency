{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadbadi/Clustering_Frequency/blob/main/Code%20Sections/5.3%20Data%20Cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0697051",
      "metadata": {
        "id": "e0697051",
        "papermill": {
          "duration": 0.001846,
          "end_time": "2025-03-17T11:53:07.751896",
          "exception": false,
          "start_time": "2025-03-17T11:53:07.750050",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### **5.3 Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "99ec6623",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-17T11:53:07.757483Z",
          "iopub.status.busy": "2025-03-17T11:53:07.756991Z",
          "iopub.status.idle": "2025-03-17T11:53:12.736588Z",
          "shell.execute_reply": "2025-03-17T11:53:12.735226Z"
        },
        "id": "99ec6623",
        "outputId": "87279070-7149-4967-ac13-47c410e7b2d3",
        "papermill": {
          "duration": 4.984662,
          "end_time": "2025-03-17T11:53:12.738465",
          "exception": false,
          "start_time": "2025-03-17T11:53:07.753803",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<table style='border-collapse: collapse; width: 100%; font-size: 18px;'>\n",
              "    <thead style='background-color: #4CAF50; color: white;'>\n",
              "        <tr>\n",
              "            <th colspan=\"5\" style=\"text-align: center; font-size: 24px; background-color: #2f4f4f; color: white;\">\n",
              "                5.3 Data Cleaning\n",
              "            </th>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <th>Step Taken</th>\n",
              "            <th>Before Action</th>\n",
              "            <th>Affected by Action</th>\n",
              "            <th>After Action</th>\n",
              "            <th>Unit</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "\n",
              "        <tr style='border: 1px solid #dddddd;'>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Step 1: Load Dataset</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>69576</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>0</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>69576</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Rows</td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style='border: 1px solid #dddddd;'>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Step 2: Remove TRUE DUPLICATE Records</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>69576</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>6750</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62826</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Rows</td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style='border: 1px solid #dddddd;'>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Step 3: Drop Rows with Missing Data</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62826</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>739</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62087</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Rows</td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style='border: 1px solid #dddddd;'>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Step 4: Strip Leading/Trailing Spaces</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62087</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62087</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62087</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Rows</td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style='border: 1px solid #dddddd;'>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Step 5: Remove Leading Apostrophes</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62087</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>0</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62087</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Rows</td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style='border: 1px solid #dddddd;'>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Step 6: Match & Replace 'NSA' Values</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62087</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>26</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62087</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Rows</td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style='border: 1px solid #dddddd;'>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Step 7: Remove Remaining 'NSA' Rows</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62087</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>29</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62058</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Rows</td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style='border: 1px solid #dddddd;'>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Step 8: Format Longitude & Latitude to 7 Decimals</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62058</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62058</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>62058</td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Rows</td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style='border: 1px solid #dddddd;'>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Rows Affected in <strong>5.3 Data Cleaning </strong></td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Initial Load:<br><strong>69576</strong></td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Overall Reduction:<br><strong>7518</strong></td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Final Count:<br><strong>62058</strong></td>\n",
              "            <td style='border: 1px solid #dddddd; padding: 8px;'>Rows</td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style='border: 1px solid #dddddd;'>\n",
              "            <td colspan=\"5\" style='border: 1px solid #dddddd; padding: 8px;'><strong>Note: Longitude and Latitude were reduced to 7 Decimal Places as,<br>• 7 decimal places offer precision of <span style='color: green;'>1.1 cm</span>, precise enough for GPS devices.<br>• Further granularity adds processing time and energy consumption without real-world benefits.<br>The final cleaned data has been saved as <span style='color: blue;'> 'Cleaned_Data.csv' </span> for further analysis.</strong></td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1ff298cd-0c2d-4854-907e-c5b1409c9adf\", \"5.3 Data Cleaning.html\", 5529)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0cdd09af-6044-4dd7-b232-826961dd1dfa\", \"Cleaned_Data.csv\", 18326982)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import warnings                                                                   # Import necessary libraries\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "from google.colab import files\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)                    # Ignore Deprecation Warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)                         # Ignore future warnings\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/mohammadbadi/CrimeAnalytics_Clustering/refs/heads/main/Output_CSV/Target_Dataset.csv\"    # Read the data from CSV file\n",
        "Data_Preparing_df = pd.read_csv(url, low_memory=False).copy()\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "html_output_filename = '/content/5.3 Data Cleaning.html'                          # Output File Name for HTML summary changed to \"5.3 Data Cleaning\"\n",
        "\n",
        "steps_summary = []                                                                # Table to store results\n",
        "\n",
        "before_step_1 = Data_Preparing_df.shape[0]                                        # Step 1: Dataset Loading\n",
        "steps_summary.append({\n",
        "    \"Step Taken\": \"Step 1: Load Dataset\",\n",
        "    \"Before Action\": before_step_1,\n",
        "    \"Affected by Action\": 0,\n",
        "    \"After Action\": before_step_1,\n",
        "    \"Unit\": \"Rows\"\n",
        "})\n",
        "\n",
        "columns_to_check = [col for col in Data_Preparing_df.columns if col != '_id']     # Step 2: Identify and remove true duplicates (excluding '_id')\n",
        "duplicate_count = Data_Preparing_df.duplicated(subset=columns_to_check).sum()\n",
        "rows_before_dedup = Data_Preparing_df.shape[0]\n",
        "Data_Preparing_df = Data_Preparing_df.drop_duplicates(subset=columns_to_check, keep='first').copy()\n",
        "rows_after_dedup = Data_Preparing_df.shape[0]\n",
        "steps_summary.append({\n",
        "    \"Step Taken\": \"Step 2: Remove TRUE DUPLICATE Records\",\n",
        "    \"Before Action\": rows_before_dedup,\n",
        "    \"Affected by Action\": duplicate_count,\n",
        "    \"After Action\": rows_after_dedup,\n",
        "    \"Unit\": \"Rows\"\n",
        "})\n",
        "\n",
        "before_drop_rows = Data_Preparing_df.shape[0]                                     # Step 3: Drop rows with null, NaN, or missing data\n",
        "Data_Preparing_df = Data_Preparing_df.dropna().copy()\n",
        "after_drop_rows = Data_Preparing_df.shape[0]\n",
        "steps_summary.append({\n",
        "    \"Step Taken\": \"Step 3: Drop Rows with Missing Data\",\n",
        "    \"Before Action\": before_drop_rows,\n",
        "    \"Affected by Action\": before_drop_rows - after_drop_rows,\n",
        "    \"After Action\": after_drop_rows,\n",
        "    \"Unit\": \"Rows\"\n",
        "})\n",
        "\n",
        "obj_cols = Data_Preparing_df.select_dtypes(include=\"object\").columns              # Step 4: Strip leading and trailing spaces from string columns\n",
        "orig_step4 = Data_Preparing_df[obj_cols].copy()\n",
        "Data_Preparing_df[obj_cols] = Data_Preparing_df[obj_cols].apply(lambda s: s.str.strip())\n",
        "affected_step4 = (orig_step4 != Data_Preparing_df[obj_cols]).any(axis=1).sum()\n",
        "steps_summary.append({\n",
        "    \"Step Taken\": \"Step 4: Strip Leading/Trailing Spaces\",\n",
        "    \"Before Action\": after_drop_rows,\n",
        "    \"Affected by Action\": affected_step4,\n",
        "    \"After Action\": after_drop_rows,\n",
        "    \"Unit\": \"Rows\"\n",
        "})\n",
        "\n",
        "orig_step5 = Data_Preparing_df[obj_cols].copy()                                   # Step 5: Remove leading apostrophes from string columns\n",
        "Data_Preparing_df[obj_cols] = Data_Preparing_df[obj_cols].apply(lambda s: s.str.lstrip(\"'\"))\n",
        "affected_step5 = (orig_step5 != Data_Preparing_df[obj_cols]).any(axis=1).sum()\n",
        "steps_summary.append({\n",
        "    \"Step Taken\": \"Step 5: Remove Leading Apostrophes\",\n",
        "    \"Before Action\": after_drop_rows,\n",
        "    \"Affected by Action\": affected_step5,\n",
        "    \"After Action\": after_drop_rows,\n",
        "    \"Unit\": \"Rows\"\n",
        "})\n",
        "\n",
        "nsa_replaced_count = 0                                                            # Step 6: Match rows where 'HOOD_158' is 'NSA' and replace with matching value based on coordinates\n",
        "for i, row in Data_Preparing_df[Data_Preparing_df['HOOD_158'] == 'NSA'].iterrows():\n",
        "    match = Data_Preparing_df[\n",
        "        (Data_Preparing_df['LONG_WGS84'] == row['LONG_WGS84']) &\n",
        "        (Data_Preparing_df['LAT_WGS84'] == row['LAT_WGS84']) &\n",
        "        (Data_Preparing_df['HOOD_158'] != 'NSA')\n",
        "    ]\n",
        "    if not match.empty:\n",
        "        matched_value = match.iloc[0]['HOOD_158']\n",
        "        Data_Preparing_df.loc[i, 'HOOD_158'] = matched_value\n",
        "        nsa_replaced_count += 1\n",
        "steps_summary.append({\n",
        "    \"Step Taken\": \"Step 6: Match & Replace 'NSA' Values\",\n",
        "    \"Before Action\": after_drop_rows,\n",
        "    \"Affected by Action\": nsa_replaced_count,\n",
        "    \"After Action\": after_drop_rows,\n",
        "    \"Unit\": \"Rows\"\n",
        "})\n",
        "\n",
        "mask_remaining_nsa = (Data_Preparing_df['HOOD_158'] == 'NSA') | (Data_Preparing_df['NEIGHBOURHOOD_158'] == 'NSA')     # Step 7: Remove remaining rows where 'HOOD_158' or 'NEIGHBOURHOOD_158' contains 'NSA'\n",
        "remaining_nsa_count = mask_remaining_nsa.sum()\n",
        "before_removal = Data_Preparing_df.shape[0]\n",
        "Data_Preparing_df = Data_Preparing_df[~mask_remaining_nsa].copy()\n",
        "after_removal = Data_Preparing_df.shape[0]\n",
        "steps_summary.append({\n",
        "    \"Step Taken\": \"Step 7: Remove Remaining 'NSA' Rows\",\n",
        "    \"Before Action\": before_removal,\n",
        "    \"Affected by Action\": remaining_nsa_count,\n",
        "    \"After Action\": after_removal,\n",
        "    \"Unit\": \"Rows\"\n",
        "})\n",
        "\n",
        "orig_long = Data_Preparing_df['LONG_WGS84'].copy()                                # Step 8: Format Longitude & Latitude to 7 decimals\n",
        "orig_lat = Data_Preparing_df['LAT_WGS84'].copy()\n",
        "Data_Preparing_df.loc[:, 'LONG_WGS84'] = Data_Preparing_df['LONG_WGS84'].astype(float).map(lambda x: f\"{x:.7f}\")\n",
        "Data_Preparing_df.loc[:, 'LAT_WGS84'] = Data_Preparing_df['LAT_WGS84'].astype(float).map(lambda x: f\"{x:.7f}\")\n",
        "affected_step8 = ((orig_long != Data_Preparing_df['LONG_WGS84']) | (orig_lat != Data_Preparing_df['LAT_WGS84'])).sum()\n",
        "steps_summary.append({\n",
        "    \"Step Taken\": \"Step 8: Format Longitude & Latitude to 7 Decimals\",\n",
        "    \"Before Action\": after_removal,\n",
        "    \"Affected by Action\": affected_step8,\n",
        "    \"After Action\": after_removal,\n",
        "    \"Unit\": \"Rows\"\n",
        "})\n",
        "\n",
        "final_row_count = Data_Preparing_df.shape[0]                                      # Final row: Rows Affected in 5.3 Data Cleaning\n",
        "steps_summary.append({\n",
        "    \"Step Taken\": \"Rows Affected in <strong>5.3 Data Cleaning </strong>\",\n",
        "    \"Before Action\": \"Initial Load:<br><strong>\" + str(before_step_1) + \"</strong>\",\n",
        "    \"Affected by Action\": \"Overall Reduction:<br><strong>\" + str(before_step_1 - final_row_count) + \"</strong>\",\n",
        "    \"After Action\": \"Final Count:<br><strong>\" + str(final_row_count) + \"</strong>\",\n",
        "    \"Unit\": \"Rows\"\n",
        "})\n",
        "                                                                                  # Build HTML Table with styling\n",
        "html_table = \"\"\"\n",
        "<table style='border-collapse: collapse; width: 100%; font-size: 18px;'>\n",
        "    <thead style='background-color: #4CAF50; color: white;'>\n",
        "        <tr>\n",
        "            <th colspan=\"5\" style=\"text-align: center; font-size: 24px; background-color: #2f4f4f; color: white;\">\n",
        "                5.3 Data Cleaning\n",
        "            </th>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <th>Step Taken</th>\n",
        "            <th>Before Action</th>\n",
        "            <th>Affected by Action</th>\n",
        "            <th>After Action</th>\n",
        "            <th>Unit</th>\n",
        "        </tr>\n",
        "    </thead>\n",
        "    <tbody>\n",
        "\"\"\"\n",
        "for step in steps_summary:\n",
        "    html_table += f\"\"\"\n",
        "        <tr style='border: 1px solid #dddddd;'>\n",
        "            <td style='border: 1px solid #dddddd; padding: 8px;'>{step['Step Taken']}</td>\n",
        "            <td style='border: 1px solid #dddddd; padding: 8px;'>{step['Before Action']}</td>\n",
        "            <td style='border: 1px solid #dddddd; padding: 8px;'>{step['Affected by Action']}</td>\n",
        "            <td style='border: 1px solid #dddddd; padding: 8px;'>{step['After Action']}</td>\n",
        "            <td style='border: 1px solid #dddddd; padding: 8px;'>{step['Unit']}</td>\n",
        "        </tr>\n",
        "    \"\"\"\n",
        "note_text = (                                                                     # Add final note row spanning all columns with the required note text\n",
        "    \"<strong>Note: \"\n",
        "    \"Longitude and Latitude were reduced to 7 Decimal Places as,<br>\"\n",
        "    \"• 7 decimal places offer precision of <span style='color: green;'>1.1 cm</span>, precise enough for GPS devices.<br>\"\n",
        "    \"• Further granularity adds processing time and energy consumption without real-world benefits.<br>\"\n",
        "    \"The final cleaned data has been saved as <span style='color: blue;'> 'Cleaned_Data.csv' </span> for further analysis.</strong>\"\n",
        ")\n",
        "html_table += f\"\"\"\n",
        "        <tr style='border: 1px solid #dddddd;'>\n",
        "            <td colspan=\"5\" style='border: 1px solid #dddddd; padding: 8px;'>{note_text}</td>\n",
        "        </tr>\n",
        "    </tbody>\n",
        "</table>\n",
        "\"\"\"\n",
        "\n",
        "Data_Preparing_df.to_csv('Cleaned_Data.csv', index=False)                         # Save the cleaned data to a new CSV file\n",
        "\n",
        "display(HTML(html_table))                                                         # Display the HTML table\n",
        "\n",
        "with open(html_output_filename, 'w', encoding='utf-8') as f:                      # Save the HTML table to a file\n",
        "    f.write(html_table)\n",
        "files.download(html_output_filename)                                              # Download the HTML file\n",
        "files.download('Cleaned_Data.csv')                                                # Download the cleaned CSV file\n",
        "print(\"\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 6888578,
          "sourceId": 11056653,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 8.500732,
      "end_time": "2025-03-17T11:53:13.361641",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-03-17T11:53:04.860909",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}